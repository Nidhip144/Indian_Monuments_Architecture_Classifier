{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUbFoTa2W0JU",
        "outputId": "7889005f-27f7-4978-8820-002e83a22ada"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "import numpy\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "9lHbRlWNc_c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1EyWne37BO8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Data\"\n",
        "files = os.listdir(path)\n",
        "orb = cv2.ORB_create()\n",
        "#sift = cv2.xfeatures2d.SIFT_create()\n",
        "X=numpy.zeros(shape=(1,500*32))\n",
        "Y=numpy.zeros(shape=(1,))\n",
        "count=-1\n",
        "for f in files:\n",
        "      if not (f.startswith('.')):\n",
        "        folder = os.path.join(path, f)\n",
        "        filenames = os.listdir(folder)\n",
        "        count+=1\n",
        "        for fi in filenames:\n",
        "            if not (fi.startswith('.')):\n",
        "                filepath = os.path.join(folder, fi)\n",
        "                #print filepath\n",
        "                image = cv2.imread(filepath, 0)\n",
        "                kp, features = orb.detectAndCompute(image,None)\n",
        "                #print features.shape\n",
        "                features=features.reshape(1,500*32)\n",
        "                #print features.shape\n",
        "                X = numpy.vstack((X, features))\n",
        "                Y=numpy.vstack((Y,numpy.asarray([count])))\n",
        "#print X.shape\n",
        "Y=Y.reshape(Y.shape[0],)"
      ],
      "metadata": {
        "id": "1VNZGshZdHgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"printing data shape {}\".format(X.shape))\n",
        "\n",
        "# Splitting the data into train and test sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Training the Random Forest Classifier\n",
        "K = 1000\n",
        "clf1 = RandomForestClassifier(n_estimators=K)\n",
        "clf1.fit(X_train, Y_train)\n",
        "\n",
        "# Evaluating the model\n",
        "y_pred = clf1.predict(X_test)\n",
        "print(\"Accuracy on test set: {}\".format(accuracy_score(Y_test, y_pred)))\n",
        "# Predicting for custom input file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "pTGfU_1fdqsk",
        "outputId": "350e2a48-81d3-4811-da8b-fd7ed7a2b9a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "printing data shape (548, 16000)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4a2706b7e8ab>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mclf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Evaluating the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"model_RandomForest.pickle\""
      ],
      "metadata": {
        "id": "7r9Xj75ofMwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(clf1, open(filename, \"wb\"))"
      ],
      "metadata": {
        "id": "w5CpU2zKfWb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
        "C_score = []\n",
        "grid = numpy.arange(0.01, 3, 0.1)\n",
        "for K in grid:\n",
        "    clf2 = SVC(C=K)\n",
        "    # Calculate the mean scores for each value of hyperparameter C\n",
        "    scores = cross_val_score(clf2, X_train, Y_train, cv=5)\n",
        "    print(scores.mean())\n",
        "    C_score.append(scores.mean())\n",
        "\n",
        "# Display the maximum score achieved at which hyperparameter value\n",
        "print (\" max score is \", max(C_score), \" at C = \", grid[C_score.index(max(C_score))])\n",
        "clf2 = SVC(C=grid[C_score.index(max(C_score))])\n",
        "clf2.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "YA8mUpC4ftpB",
        "outputId": "aa7b9eee-76fe-4b3a-f239-75cca640b654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2206960385042577\n",
            "0.2206960385042577\n",
            "0.2206960385042577\n",
            "0.2206960385042577\n",
            "0.2206960385042577\n",
            "0.2206960385042577\n",
            "0.22339874120696038\n",
            "0.22613846723435765\n",
            "0.22613846723435765\n",
            "0.23706034801925213\n",
            "0.2589041095890411\n",
            "0.29163272861903\n",
            "0.30529433543132173\n",
            "0.31884487226952984\n",
            "0.32428730099962977\n",
            "0.32428730099962977\n",
            "0.32428730099962977\n",
            "0.32428730099962977\n",
            "0.32428730099962977\n",
            "0.32428730099962977\n",
            "0.32428730099962977\n",
            "0.32428730099962977\n",
            "0.32428730099962977\n",
            "0.32428730099962977\n",
            "0.32428730099962977\n",
            "0.32428730099962977\n",
            "0.32428730099962977\n",
            "0.32428730099962977\n",
            "0.32428730099962977\n",
            "0.32428730099962977\n",
            " max score is  0.32428730099962977  at C =  1.4100000000000001\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.4100000000000001)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1.4100000000000001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1.4100000000000001)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"model_SVM.pickle\""
      ],
      "metadata": {
        "id": "Moc45SqXgtBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(clf2, open(filename, \"wb\"))"
      ],
      "metadata": {
        "id": "NXMnLvDvgxup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x2uMSUUuaXn",
        "outputId": "3029d4c4-a256-4bd4-c541-b6a200b15f2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define data directories\n",
        "train_data_dir = '/content/drive/MyDrive/Data1/train'\n",
        "validation_data_dir = '/content/drive/MyDrive/Data1/valid'\n",
        "\n",
        "# Define image preprocessing parameters\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Define batch size and image dimensions\n",
        "batch_size = 32\n",
        "img_height = 64\n",
        "img_width = 64\n",
        "\n",
        "# Load and preprocess training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Load and preprocess validation data\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXCL-X3nBUNp",
        "outputId": "f9527336-b879-45d6-c186-0ee689a3889c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 380 images belonging to 5 classes.\n",
            "Found 108 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
        "                 input_shape=(64, 64, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dense(units=5, activation='softmax'))  # Adjusted units for 5 classes\n",
        "\n",
        "model.add(BatchNormalization(axis=1))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYDyTBJwBprI",
        "outputId": "6b08d5c4-0bfd-4305-fb69-8ef63c829969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 64, 64, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 31, 31, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3136)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              3137000   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 5005      \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 5)                 20        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3180745 (12.13 MB)\n",
            "Trainable params: 3180735 (12.13 MB)\n",
            "Non-trainable params: 10 (40.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "print(f'Validation Loss: {loss}, Validation Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emRgtZz6Bwse",
        "outputId": "90e320f5-c896-4a4b-e22c-65e0eac283bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 109s 10s/step - loss: 8.3727 - accuracy: 0.1466 - val_loss: 8.7952 - val_accuracy: 0.1875\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 9s 836ms/step - loss: 9.6154 - accuracy: 0.1925 - val_loss: 8.3656 - val_accuracy: 0.1875\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 7s 641ms/step - loss: nan - accuracy: 0.2270 - val_loss: 8.2764 - val_accuracy: 0.1979\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 8s 718ms/step - loss: 10.4877 - accuracy: 0.1724 - val_loss: 7.9586 - val_accuracy: 0.1979\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 8s 674ms/step - loss: 9.2237 - accuracy: 0.1839 - val_loss: 7.6781 - val_accuracy: 0.2396\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 8s 684ms/step - loss: nan - accuracy: 0.2098 - val_loss: 7.2459 - val_accuracy: 0.2396\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 9s 842ms/step - loss: 9.2696 - accuracy: 0.2213 - val_loss: 7.4151 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 7s 608ms/step - loss: nan - accuracy: 0.2155 - val_loss: 7.3935 - val_accuracy: 0.2396\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 9s 846ms/step - loss: 10.3400 - accuracy: 0.1897 - val_loss: 7.1220 - val_accuracy: 0.2292\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 7s 642ms/step - loss: 10.0065 - accuracy: 0.1983 - val_loss: 7.2337 - val_accuracy: 0.2292\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 8s 720ms/step - loss: 9.9093 - accuracy: 0.2241 - val_loss: 6.7455 - val_accuracy: 0.2500\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 9s 855ms/step - loss: 10.0465 - accuracy: 0.1954 - val_loss: 6.8978 - val_accuracy: 0.2604\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 7s 637ms/step - loss: 10.0973 - accuracy: 0.2040 - val_loss: 7.3861 - val_accuracy: 0.2292\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 7s 637ms/step - loss: 9.3595 - accuracy: 0.2098 - val_loss: 6.7343 - val_accuracy: 0.2812\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 10s 902ms/step - loss: 8.7685 - accuracy: 0.2213 - val_loss: 6.9021 - val_accuracy: 0.2396\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 7s 628ms/step - loss: nan - accuracy: 0.2069 - val_loss: 6.7816 - val_accuracy: 0.2708\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 9s 835ms/step - loss: nan - accuracy: 0.1954 - val_loss: 6.9650 - val_accuracy: 0.2812\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 7s 583ms/step - loss: 9.2125 - accuracy: 0.2126 - val_loss: 7.2538 - val_accuracy: 0.2188\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 9s 804ms/step - loss: 10.1340 - accuracy: 0.2184 - val_loss: 6.4059 - val_accuracy: 0.2708\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 7s 627ms/step - loss: nan - accuracy: 0.2356 - val_loss: 6.8394 - val_accuracy: 0.2500\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 9s 794ms/step - loss: 9.5355 - accuracy: 0.2155 - val_loss: 6.6643 - val_accuracy: 0.2500\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 9s 801ms/step - loss: 8.9436 - accuracy: 0.1818 - val_loss: 6.6064 - val_accuracy: 0.2604\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 7s 602ms/step - loss: 9.4023 - accuracy: 0.2155 - val_loss: 6.9097 - val_accuracy: 0.2396\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 9s 781ms/step - loss: 8.9515 - accuracy: 0.2040 - val_loss: 6.7058 - val_accuracy: 0.2500\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 7s 593ms/step - loss: 10.0514 - accuracy: 0.1983 - val_loss: 6.2196 - val_accuracy: 0.2604\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 7s 595ms/step - loss: 9.3489 - accuracy: 0.1954 - val_loss: 6.6483 - val_accuracy: 0.2500\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 9s 795ms/step - loss: 9.3275 - accuracy: 0.1925 - val_loss: 6.0131 - val_accuracy: 0.2604\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 8s 714ms/step - loss: 9.7366 - accuracy: 0.2069 - val_loss: 6.2740 - val_accuracy: 0.2604\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 7s 635ms/step - loss: nan - accuracy: 0.2299 - val_loss: 6.7785 - val_accuracy: 0.2188\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 9s 874ms/step - loss: nan - accuracy: 0.2126 - val_loss: 6.3761 - val_accuracy: 0.2604\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 7s 622ms/step - loss: 8.8955 - accuracy: 0.1925 - val_loss: 6.8183 - val_accuracy: 0.2396\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 9s 840ms/step - loss: 9.3551 - accuracy: 0.1724 - val_loss: 6.5113 - val_accuracy: 0.2292\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 7s 631ms/step - loss: 9.8319 - accuracy: 0.2213 - val_loss: 6.2654 - val_accuracy: 0.2708\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 7s 624ms/step - loss: 9.0289 - accuracy: 0.2358 - val_loss: 6.1275 - val_accuracy: 0.2500\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 9s 831ms/step - loss: 9.4109 - accuracy: 0.1925 - val_loss: 6.6977 - val_accuracy: 0.2500\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 7s 627ms/step - loss: nan - accuracy: 0.1753 - val_loss: 6.1849 - val_accuracy: 0.2708\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 9s 829ms/step - loss: 9.3496 - accuracy: 0.2385 - val_loss: 6.6689 - val_accuracy: 0.2396\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 7s 620ms/step - loss: 9.7203 - accuracy: 0.1466 - val_loss: 6.3539 - val_accuracy: 0.2292\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 8s 718ms/step - loss: nan - accuracy: 0.2155 - val_loss: 5.8260 - val_accuracy: 0.2604\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 10s 886ms/step - loss: nan - accuracy: 0.1818 - val_loss: 6.4388 - val_accuracy: 0.2396\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 7s 637ms/step - loss: 10.3131 - accuracy: 0.2126 - val_loss: 6.0810 - val_accuracy: 0.2604\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 9s 839ms/step - loss: 9.0309 - accuracy: 0.1868 - val_loss: 6.3889 - val_accuracy: 0.2396\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 7s 591ms/step - loss: 9.4927 - accuracy: 0.2213 - val_loss: 6.2123 - val_accuracy: 0.2396\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 9s 777ms/step - loss: 8.9986 - accuracy: 0.1983 - val_loss: 6.3575 - val_accuracy: 0.2292\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 7s 603ms/step - loss: nan - accuracy: 0.1897 - val_loss: 6.1362 - val_accuracy: 0.2604\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 9s 767ms/step - loss: 8.8575 - accuracy: 0.2557 - val_loss: 6.1334 - val_accuracy: 0.2396\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 7s 633ms/step - loss: 10.0501 - accuracy: 0.1753 - val_loss: 6.1079 - val_accuracy: 0.2500\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 8s 725ms/step - loss: nan - accuracy: 0.2126 - val_loss: 5.8908 - val_accuracy: 0.2812\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 8s 727ms/step - loss: 9.6325 - accuracy: 0.2213 - val_loss: 6.0526 - val_accuracy: 0.2604\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 8s 650ms/step - loss: 9.1772 - accuracy: 0.2098 - val_loss: 6.2083 - val_accuracy: 0.2500\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 9s 799ms/step - loss: 9.0818 - accuracy: 0.2011 - val_loss: 6.3407 - val_accuracy: 0.2292\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 7s 608ms/step - loss: nan - accuracy: 0.2069 - val_loss: 5.8180 - val_accuracy: 0.2604\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 7s 631ms/step - loss: nan - accuracy: 0.1925 - val_loss: 5.9475 - val_accuracy: 0.2604\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 9s 818ms/step - loss: nan - accuracy: 0.2155 - val_loss: 5.6621 - val_accuracy: 0.2500\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 7s 627ms/step - loss: 9.7244 - accuracy: 0.2155 - val_loss: 5.7923 - val_accuracy: 0.2500\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 7s 630ms/step - loss: nan - accuracy: 0.2184 - val_loss: 6.2653 - val_accuracy: 0.2396\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 9s 753ms/step - loss: nan - accuracy: 0.2213 - val_loss: 5.7692 - val_accuracy: 0.2396\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 8s 724ms/step - loss: nan - accuracy: 0.2011 - val_loss: 5.2690 - val_accuracy: 0.2500\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 7s 578ms/step - loss: 9.7264 - accuracy: 0.2011 - val_loss: 6.0966 - val_accuracy: 0.2396\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 9s 837ms/step - loss: 9.9254 - accuracy: 0.1932 - val_loss: 6.2646 - val_accuracy: 0.1354\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 7s 586ms/step - loss: 9.9617 - accuracy: 0.1753 - val_loss: 5.9800 - val_accuracy: 0.2396\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 9s 747ms/step - loss: nan - accuracy: 0.1868 - val_loss: 6.0033 - val_accuracy: 0.2604\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 9s 832ms/step - loss: 9.8116 - accuracy: 0.2069 - val_loss: 5.6285 - val_accuracy: 0.2604\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 7s 648ms/step - loss: 8.9798 - accuracy: 0.2074 - val_loss: 6.1286 - val_accuracy: 0.1250\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 7s 642ms/step - loss: 9.9068 - accuracy: 0.2126 - val_loss: 5.9696 - val_accuracy: 0.1458\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 9s 836ms/step - loss: nan - accuracy: 0.2069 - val_loss: 6.0365 - val_accuracy: 0.1354\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 7s 590ms/step - loss: 8.9531 - accuracy: 0.1960 - val_loss: 6.4857 - val_accuracy: 0.2396\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 9s 816ms/step - loss: 9.1754 - accuracy: 0.2241 - val_loss: 6.0172 - val_accuracy: 0.2708\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 7s 642ms/step - loss: 9.0293 - accuracy: 0.2155 - val_loss: 5.9608 - val_accuracy: 0.1562\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 8s 701ms/step - loss: 9.4427 - accuracy: 0.1897 - val_loss: 6.7162 - val_accuracy: 0.2292\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 7s 678ms/step - loss: 9.5756 - accuracy: 0.2155 - val_loss: 10.0738 - val_accuracy: 0.2188\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 7s 624ms/step - loss: nan - accuracy: 0.2155 - val_loss: 10.0738 - val_accuracy: 0.2500\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 9s 801ms/step - loss: 10.0370 - accuracy: 0.2040 - val_loss: 8.8985 - val_accuracy: 0.1667\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 7s 630ms/step - loss: 9.0358 - accuracy: 0.1925 - val_loss: 10.2417 - val_accuracy: 0.1562\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 7s 655ms/step - loss: 9.7666 - accuracy: 0.2069 - val_loss: 9.4022 - val_accuracy: 0.1354\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 7s 625ms/step - loss: nan - accuracy: 0.1983 - val_loss: 9.9059 - val_accuracy: 0.2292\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 9s 831ms/step - loss: 9.8696 - accuracy: 0.1925 - val_loss: 10.0738 - val_accuracy: 0.2188\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 7s 638ms/step - loss: nan - accuracy: 0.2299 - val_loss: 9.7380 - val_accuracy: 0.1562\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 9s 795ms/step - loss: nan - accuracy: 0.2126 - val_loss: 9.7380 - val_accuracy: 0.2604\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 7s 648ms/step - loss: 9.2959 - accuracy: 0.2017 - val_loss: 9.7380 - val_accuracy: 0.1458\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 7s 630ms/step - loss: 8.8894 - accuracy: 0.2270 - val_loss: 9.7380 - val_accuracy: 0.2292\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 8s 658ms/step - loss: 9.5496 - accuracy: 0.2213 - val_loss: 9.9059 - val_accuracy: 0.2188\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 9s 830ms/step - loss: 9.2634 - accuracy: 0.2184 - val_loss: 9.5701 - val_accuracy: 0.1458\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 7s 635ms/step - loss: 9.2309 - accuracy: 0.2069 - val_loss: 9.9059 - val_accuracy: 0.1458\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 9s 820ms/step - loss: nan - accuracy: 0.1954 - val_loss: 9.5701 - val_accuracy: 0.2604\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 7s 636ms/step - loss: 9.2328 - accuracy: 0.2213 - val_loss: 10.0738 - val_accuracy: 0.2396\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 8s 732ms/step - loss: nan - accuracy: 0.2098 - val_loss: 9.5701 - val_accuracy: 0.2500\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 8s 774ms/step - loss: 9.6072 - accuracy: 0.2045 - val_loss: 9.4022 - val_accuracy: 0.2812\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 7s 628ms/step - loss: 9.5440 - accuracy: 0.1897 - val_loss: 9.4022 - val_accuracy: 0.1562\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 8s 712ms/step - loss: 8.7884 - accuracy: 0.2241 - val_loss: 9.4022 - val_accuracy: 0.1562\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 7s 651ms/step - loss: nan - accuracy: 0.2126 - val_loss: 9.9059 - val_accuracy: 0.2292\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 8s 720ms/step - loss: 9.4876 - accuracy: 0.1954 - val_loss: 9.7380 - val_accuracy: 0.1562\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 7s 639ms/step - loss: 9.1867 - accuracy: 0.2270 - val_loss: 9.7380 - val_accuracy: 0.2396\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 7s 643ms/step - loss: nan - accuracy: 0.2184 - val_loss: 9.9059 - val_accuracy: 0.1354\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 7s 624ms/step - loss: 9.6430 - accuracy: 0.1954 - val_loss: 9.5701 - val_accuracy: 0.2604\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 9s 841ms/step - loss: nan - accuracy: 0.1868 - val_loss: 9.7380 - val_accuracy: 0.2500\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 7s 609ms/step - loss: 9.1839 - accuracy: 0.2040 - val_loss: 9.5701 - val_accuracy: 0.2500\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 8s 661ms/step - loss: nan - accuracy: 0.1983 - val_loss: 9.7380 - val_accuracy: 0.2500\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 9s 793ms/step - loss: 10.0076 - accuracy: 0.1695 - val_loss: 9.4022 - val_accuracy: 0.1562\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 7s 587ms/step - loss: 9.1657 - accuracy: 0.2011 - val_loss: 9.7380 - val_accuracy: 0.1562\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 9.7007 - accuracy: 0.1481\n",
            "Validation Loss: 9.700706481933594, Validation Accuracy: 0.14814814925193787\n"
          ]
        }
      ]
    }
  ]
}